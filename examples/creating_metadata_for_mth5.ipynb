{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of Creating Metadata for MTH5\n",
    "\n",
    "This example will cover producing MTH5 metadata from various inputs.\n",
    "\n",
    "These examples will work for any mth5.metadata class object.  Of importance to an MT survey are:\n",
    "    - Survey\n",
    "    - Station\n",
    "    - Run\n",
    "    - Electric\n",
    "    - Magnetic\n",
    "    - Auxiliary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-04T10:36:52 [line 23] mth5.<module> - INFO: Started MTH5\n",
      "2020-12-04T10:36:52 [line 28] mth5.<module> - INFO: Debug Log file can be found at c:\\Users\\jpeacock\\Documents\\GitHub\\mth5\\mth5_debug.log\n",
      "2020-12-04T10:36:52 [line 29] mth5.<module> - INFO: Error Log file can be found at c:\\Users\\jpeacock\\Documents\\GitHub\\mth5\\mth5_error.log\n"
     ]
    }
   ],
   "source": [
    "# this is a hack for now, once we have a real package with an install this should be removed.\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# change this to your local mth5 repository\n",
    "os.chdir(r\"c:\\Users\\jpeacock\\Documents\\GitHub\\mth5\")\n",
    "\n",
    "# import mth5 metadata\n",
    "from mth5 import metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Note*: \n",
    "\n",
    "The important part of the metadata is to make sure that the key names match the standards, otherwise you will run into some issues.  If you do not know what the standard keys are for a particular metadata instance you can always do the following.  This will work for any mth5.metadata class objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['acquired_by.author',\n",
       " 'acquired_by.comments',\n",
       " 'citation_dataset.doi',\n",
       " 'citation_journal.doi',\n",
       " 'comments',\n",
       " 'country',\n",
       " 'datum',\n",
       " 'fdsn.channel_code',\n",
       " 'fdsn.id',\n",
       " 'fdsn.network',\n",
       " 'fdsn.new_epoch',\n",
       " 'geographic_name',\n",
       " 'name',\n",
       " 'northwest_corner.latitude',\n",
       " 'northwest_corner.longitude',\n",
       " 'project',\n",
       " 'project_lead.author',\n",
       " 'project_lead.email',\n",
       " 'project_lead.organization',\n",
       " 'release_license',\n",
       " 'southeast_corner.latitude',\n",
       " 'southeast_corner.longitude',\n",
       " 'summary',\n",
       " 'survey_id',\n",
       " 'time_period.end_date',\n",
       " 'time_period.start_date']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "survey = metadata.Survey()\n",
    "survey.get_attribute_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are unsure of what a key name means you can do the following to get information about a certain attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "release_license:\n",
      "\talias: []\n",
      "\tdescription: How the data can be used. The options are based on Creative Commons licenses. For details visit https://creativecommons.org/licenses/\n",
      "\texample: CC-0\n",
      "\toptions: ['CC-0', 'CC-BY', 'CC-BY-SA', 'CC-BY-ND', 'CC-BY-NC-SA', 'CC-BY-NC-ND']\n",
      "\trequired: True\n",
      "\tstyle: controlled vocabulary\n",
      "\ttype: string\n",
      "\tunits: None\n"
     ]
    }
   ],
   "source": [
    "survey.attribute_information(\"release_license\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "northwest_corner.longitude:\n",
      "\talias: ['lon', 'long']\n",
      "\tdescription: longitude of location in datum specified at survey level\n",
      "\texample: 14.23\n",
      "\toptions: []\n",
      "\trequired: True\n",
      "\tstyle: number\n",
      "\ttype: float\n",
      "\tunits: degrees\n"
     ]
    }
   ],
   "source": [
    "survey.attribute_information(\"northwest_corner.longitude\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create example files to read in\n",
    "This includes a csv and json files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " --> Wrote example to c:\\Users\\jpeacock\\Documents\\GitHub\\mth5\\example.csv\n",
      "id,location.latitude,location.longitude,location.elevation,time_period.start,time_period.end\n",
      "mt01,10.0,12.0,100,2020-01-01,2020-01-02\n",
      "mt02,15,25,150,2020-01-05,2020-01-10\n"
     ]
    }
   ],
   "source": [
    "# create an example csv string\n",
    "example_csv = [\"id,location.latitude,location.longitude,location.elevation,time_period.start,time_period.end\",\n",
    "               \"mt01,10.0,12.0,100,2020-01-01,2020-01-02\",\n",
    "               \"mt02,15,25,150,2020-01-05,2020-01-10\"]\n",
    "\n",
    "# write to a file\n",
    "example_csv_fn = Path(Path.cwd(), \"example.csv\")\n",
    "with open(example_csv_fn, 'w') as fid:\n",
    "    fid.write(\"\\n\".join(example_csv))\n",
    "print(f\" --> Wrote example to {example_csv_fn}\")\n",
    "\n",
    "print(\"\\n\".join(example_csv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " --> Wrote example to c:\\Users\\jpeacock\\Documents\\GitHub\\mth5\\example.json\n",
      "{\"station\": {\"id\": \"mt01\", \"location.elevation\": 100.0, \"location.latitude\": 10.0, \"location.longitude\": 12.0, \"time_period.end\": \"2020-01-02T00:00:00+00:00\", \"time_period.start\": \"2020-01-01T00:00:00+00:00\"}}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# create an example JSON file\n",
    "example_json = '{\"station\": {\"id\": \"mt01\", \"location.elevation\": 100.0, \"location.latitude\": 10.0, \"location.longitude\": 12.0, \"time_period.end\": \"2020-01-02T00:00:00+00:00\", \"time_period.start\": \"2020-01-01T00:00:00+00:00\"}}' \n",
    "example_json_fn = Path(Path.cwd(), \"example.json\")\n",
    "with open(example_json_fn, 'w') as fid:\n",
    "    json.dump(json.loads(example_json), fid)\n",
    "    \n",
    "print(f\" --> Wrote example to {example_json_fn}\")\n",
    "\n",
    "print(example_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create metadata from a csv file\n",
    "This would be if you have a table of metadata that were collected into something like a spreadsheet using Excel or another program."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in the csv string into a list of dictionaries that we can use to input into the metadata.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'id': 'mt01', 'location.latitude': '10.0', 'location.longitude': '12.0', 'location.elevation': '100', 'time_period.start': '2020-01-01', 'time_period.end': '2020-01-02'}, {'id': 'mt02', 'location.latitude': '15', 'location.longitude': '25', 'location.elevation': '150', 'time_period.start': '2020-01-05', 'time_period.end': '2020-01-10'}]\n"
     ]
    }
   ],
   "source": [
    "keys = example_csv[0].split(',')\n",
    "list_of_dictionaries = []\n",
    "for line in example_csv[1:]:\n",
    "    line_dict = {}\n",
    "    for key, value in zip(keys, line.split(',')):\n",
    "        line_dict[key] = value\n",
    "    list_of_dictionaries.append(line_dict)\n",
    "    \n",
    "print(list_of_dictionaries)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input into MTH5 station metadata\n",
    "\n",
    "We'll do one at a time as an example, later you can loop over each entry to create a separate metadata instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "    \"station\": {\n",
       "        \"acquired_by.author\": null,\n",
       "        \"channels_recorded\": [],\n",
       "        \"data_type\": null,\n",
       "        \"geographic_name\": null,\n",
       "        \"id\": \"mt01\",\n",
       "        \"location.declination.model\": null,\n",
       "        \"location.declination.value\": null,\n",
       "        \"location.elevation\": 100.0,\n",
       "        \"location.latitude\": 10.0,\n",
       "        \"location.longitude\": 12.0,\n",
       "        \"orientation.method\": null,\n",
       "        \"orientation.reference_frame\": \"geographic\",\n",
       "        \"provenance.creation_time\": \"2020-12-04T19:18:31.029691+00:00\",\n",
       "        \"provenance.software.author\": null,\n",
       "        \"provenance.software.name\": null,\n",
       "        \"provenance.software.version\": null,\n",
       "        \"provenance.submitter.author\": null,\n",
       "        \"provenance.submitter.email\": null,\n",
       "        \"provenance.submitter.organization\": null,\n",
       "        \"time_period.end\": \"2020-01-02T00:00:00+00:00\",\n",
       "        \"time_period.start\": \"2020-01-01T00:00:00+00:00\"\n",
       "    }\n",
       "}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_station = metadata.Station()\n",
    "csv_station.from_dict(list_of_dictionaries[0])\n",
    "csv_station"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in csv using Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     id  location.latitude  location.longitude  location.elevation  \\\n",
      "0  mt01               10.0                12.0                 100   \n",
      "1  mt02               15.0                25.0                 150   \n",
      "\n",
      "  time_period.start time_period.end  \n",
      "0        2020-01-01      2020-01-02  \n",
      "1        2020-01-05      2020-01-10  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "example_df = pd.read_csv(example_csv_fn, header=0)\n",
    "\n",
    "print(example_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "    \"station\": {\n",
       "        \"acquired_by.author\": null,\n",
       "        \"channels_recorded\": [],\n",
       "        \"data_type\": null,\n",
       "        \"geographic_name\": null,\n",
       "        \"id\": \"mt01\",\n",
       "        \"location.declination.model\": null,\n",
       "        \"location.declination.value\": null,\n",
       "        \"location.elevation\": 100.0,\n",
       "        \"location.latitude\": 10.0,\n",
       "        \"location.longitude\": 12.0,\n",
       "        \"orientation.method\": null,\n",
       "        \"orientation.reference_frame\": \"geographic\",\n",
       "        \"provenance.creation_time\": \"2020-12-04T19:18:38.060924+00:00\",\n",
       "        \"provenance.software.author\": null,\n",
       "        \"provenance.software.name\": null,\n",
       "        \"provenance.software.version\": null,\n",
       "        \"provenance.submitter.author\": null,\n",
       "        \"provenance.submitter.email\": null,\n",
       "        \"provenance.submitter.organization\": null,\n",
       "        \"time_period.end\": \"2020-01-02T00:00:00+00:00\",\n",
       "        \"time_period.start\": \"2020-01-01T00:00:00+00:00\"\n",
       "    }\n",
       "}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas_station = metadata.Station()\n",
    "pandas_station.from_dict(example_df.iloc[0].to_dict())\n",
    "pandas_station"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create metadata from JSON file\n",
    "If you have your data stored in a json file these can be read in using the json package, which reads into dictionaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'station': {'id': 'mt01', 'location.elevation': 100.0, 'location.latitude': 10.0, 'location.longitude': 12.0, 'time_period.end': '2020-01-02T00:00:00+00:00', 'time_period.start': '2020-01-01T00:00:00+00:00'}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{\n",
       "    \"station\": {\n",
       "        \"acquired_by.author\": null,\n",
       "        \"channels_recorded\": [],\n",
       "        \"data_type\": null,\n",
       "        \"geographic_name\": null,\n",
       "        \"id\": \"mt01\",\n",
       "        \"location.declination.model\": null,\n",
       "        \"location.declination.value\": null,\n",
       "        \"location.elevation\": 100.0,\n",
       "        \"location.latitude\": 10.0,\n",
       "        \"location.longitude\": 12.0,\n",
       "        \"orientation.method\": null,\n",
       "        \"orientation.reference_frame\": \"geographic\",\n",
       "        \"provenance.creation_time\": \"2020-12-04T19:25:30.486927+00:00\",\n",
       "        \"provenance.software.author\": null,\n",
       "        \"provenance.software.name\": null,\n",
       "        \"provenance.software.version\": null,\n",
       "        \"provenance.submitter.author\": null,\n",
       "        \"provenance.submitter.email\": null,\n",
       "        \"provenance.submitter.organization\": null,\n",
       "        \"time_period.end\": \"2020-01-02T00:00:00+00:00\",\n",
       "        \"time_period.start\": \"2020-01-01T00:00:00+00:00\"\n",
       "    }\n",
       "}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(example_json_fn, \"r\") as fid:\n",
    "    example_json_dict = json.load(fid)\n",
    "    \n",
    "print(example_json_dict)\n",
    "    \n",
    "station_json = metadata.Station()\n",
    "station_json.from_dict(example_json_dict)\n",
    "station_json"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "peacock",
   "language": "python",
   "name": "peacock"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
