{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "621d92cd-a1ec-4381-9ef6-4807d2608852",
   "metadata": {},
   "source": [
    "# Example 01\n",
    "This is the example code from Figure 7 in Peacock, J.R. Kappler, K, Heagy, L., Ronan, T., Kelbert, A., Frassetto, A. (2022) MTH5: an archive and exchangeable data format for magnetotelluric time series data, *Computers & Geoscience*, in review.\n",
    "\n",
    "This is an example script to read in LEMI424 files for a single station.\n",
    "\n",
    "The LEMI424 outputs files in hour blocks, so as long as the files are \n",
    "continuous all the files can be considered a single run.  Here we have 2 files of 2 minutes each starting on the hour, so 2 runs will be made.\n",
    "\n",
    "The user will have to input some metadata like station name and run id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7e0b318-57b0-42e1-83aa-90ee636e03a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from mth5 import read_file\n",
    "from mth5.mth5 import MTH5\n",
    "\n",
    "from mt_metadata.timeseries import Survey, Station"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa69a6a-4285-453d-92a9-a0fa341b95c0",
   "metadata": {},
   "source": [
    "### Set Path to LEMI 424 .TXT files\n",
    "Example files are supplied in this directory.  They are each 2 minutes long for simplicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a620d75-213b-4fa0-bef4-aca1e4f65db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemi424_dir = Path(r\".\")\n",
    "h5_fn = lemi424_dir.joinpath(\"from_lemi424.mth5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b7b9c15-013b-4a3e-82d3-ebd921548a38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Removed existing file from_lemi424.mth5\n"
     ]
    }
   ],
   "source": [
    "# remove file if it already exists\n",
    "if h5_fn.exists():\n",
    "    h5_fn.unlink()\n",
    "    print(f\"INFO: Removed existing file {h5_fn}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf568d16-e7fe-4118-8c3f-7443d7fffcab",
   "metadata": {},
   "source": [
    "### Open an MTH5 file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88758f0c-0f35-41ee-b68c-27b129502eef",
   "metadata": {},
   "source": [
    "### Add Survey Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d91e4727-a26f-4ca3-8ba2-f61da2bba6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_metadata = Survey()\n",
    "survey_metadata.acquired_by.author = \"MT Master\"\n",
    "survey_metadata.id = \"TEST01\"\n",
    "survey_metadata.fdsn.network = \"MT\"\n",
    "survey_metadata.name = \"test\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d30ba8-9be6-4a81-ab44-5332eacce20e",
   "metadata": {},
   "source": [
    "## Fill MTH5\n",
    "\n",
    "Here we will use context manager `with` to make the MTH5. This will close the file if anything in the process breaks.  \n",
    "\n",
    "We will add a Station to the Survey Group with Runs for each file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d223532-412f-444f-936c-a4ed36d6fb5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2023-09-27T16:21:47.713367-0700 | INFO | mth5.mth5 | _initialize_file | Initialized MTH5 0.2.0 file from_lemi424.mth5 in mode w\u001b[0m\n",
      "/:\n",
      "====================\n",
      "    |- Group: Experiment\n",
      "    --------------------\n",
      "        |- Group: Reports\n",
      "        -----------------\n",
      "        |- Group: Standards\n",
      "        -------------------\n",
      "            --> Dataset: summary\n",
      "            ......................\n",
      "        |- Group: Surveys\n",
      "        -----------------\n",
      "            |- Group: TEST01\n",
      "            ----------------\n",
      "                |- Group: Filters\n",
      "                -----------------\n",
      "                    |- Group: coefficient\n",
      "                    ---------------------\n",
      "                    |- Group: fap\n",
      "                    -------------\n",
      "                    |- Group: fir\n",
      "                    -------------\n",
      "                    |- Group: time_delay\n",
      "                    --------------------\n",
      "                    |- Group: zpk\n",
      "                    -------------\n",
      "                |- Group: Reports\n",
      "                -----------------\n",
      "                |- Group: Standards\n",
      "                -------------------\n",
      "                    --> Dataset: summary\n",
      "                    ......................\n",
      "                |- Group: Stations\n",
      "                ------------------\n",
      "                    |- Group: mt001\n",
      "                    ---------------\n",
      "                        |- Group: 000\n",
      "                        -------------\n",
      "                            --> Dataset: bx\n",
      "                            .................\n",
      "                            --> Dataset: by\n",
      "                            .................\n",
      "                            --> Dataset: bz\n",
      "                            .................\n",
      "                            --> Dataset: e1\n",
      "                            .................\n",
      "                            --> Dataset: e2\n",
      "                            .................\n",
      "                            --> Dataset: temperature_e\n",
      "                            ............................\n",
      "                            --> Dataset: temperature_h\n",
      "                            ............................\n",
      "                        |- Group: 001\n",
      "                        -------------\n",
      "                            --> Dataset: bx\n",
      "                            .................\n",
      "                            --> Dataset: by\n",
      "                            .................\n",
      "                            --> Dataset: bz\n",
      "                            .................\n",
      "                            --> Dataset: e1\n",
      "                            .................\n",
      "                            --> Dataset: e2\n",
      "                            .................\n",
      "                            --> Dataset: temperature_e\n",
      "                            ............................\n",
      "                            --> Dataset: temperature_h\n",
      "                            ............................\n",
      "                        |- Group: Fourier_Coefficients\n",
      "                        ------------------------------\n",
      "                        |- Group: Transfer_Functions\n",
      "                        ----------------------------\n",
      "        --> Dataset: channel_summary\n",
      "        ..............................\n",
      "        --> Dataset: tf_summary\n",
      "        .........................\n",
      "\u001b[1m2023-09-27T16:21:52.193410-0700 | INFO | mth5.mth5 | close_mth5 | Flushing and closing from_lemi424.mth5\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%timeit\n",
    "\n",
    "with MTH5() as m:\n",
    "    m.open_mth5(h5_fn, \"w\")\n",
    "\n",
    "    # add survey metadata\n",
    "    survey_group = m.add_survey(survey_metadata.id, survey_metadata)\n",
    "    # initialize a station\n",
    "    station_group = survey_group.stations_group.add_station(\"mt001\")\n",
    "\n",
    "    # loop over all files in a directory, should be a single station\n",
    "    for index, lemi424_filename in enumerate(sorted(lemi424_dir.glob(\"*.TXT\"))):\n",
    "        run_object = read_file(lemi424_filename)\n",
    "        run_object.run_metadata.id = f\"{index:003}\"\n",
    "        # make a run group from first file\n",
    "        run_group = station_group.add_run(\n",
    "            run_object.run_metadata.id, run_metadata=run_object.run_metadata\n",
    "        )\n",
    "        run_group.from_runts(run_object)\n",
    "        run_group.update_run_metadata()\n",
    "\n",
    "    # update station metadata to ensure consistency\n",
    "    station_group.update_station_metadata()\n",
    "    survey_group.update_survey_metadata()\n",
    "\n",
    "    print(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e175de22-532a-4ffa-9612-ee470b6db2cc",
   "metadata": {},
   "source": [
    "### Delete the MTH5 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80a15b94-2736-41d0-83ed-124e1074b47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "h5_fn.unlink()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
