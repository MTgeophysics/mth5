{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a v0.2.0 MTH5 file from the IRIS Data Managment Center \n",
    "\n",
    "**Note:** this example assumes that data availability (Network, Station, Channel, Start, End) are all previously known.  If you do not know the data that you want to download use [IRIS tools](https://ds.iris.edu/ds/nodes/dmc/tools/##) to get data availability.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-01 13:06:50,662 [line 135] mth5.setup_logger - INFO: Logging file can be found C:\\Users\\jpeacock\\Documents\\GitHub\\mth5\\logs\\mth5_debug.log\n"
     ]
    }
   ],
   "source": [
    "# IMPORTS\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from mth5.clients.make_mth5 import MakeMTH5\n",
    "from mth5 import mth5, timeseries\n",
    "\n",
    "from mt_metadata.utils.mttime import get_now_utc, MTime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set the path to save files to as the current working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_path = Path().cwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize a MakeMTH5 object\n",
    "\n",
    "Here, we are setting the MTH5 file version to 0.2.0 so that we can have multiple surveys in a single file.  Also, setting the client to \"IRIS\".  Here, we are using `obspy.clients` tools for the request.  Here are the available [FDSN clients](https://docs.obspy.org/packages/obspy.clients.fdsn.html). \n",
    "\n",
    "**Note:** Only the \"IRIS\" client has been tested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = MakeMTH5(mth5_version='0.2.0')\n",
    "m.client = \"IRIS\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make the data inquiry as a DataFrame\n",
    "\n",
    "There are a few ways to make the inquiry to request data.  \n",
    "\n",
    "1. Make a DataFrame by hand.  Here we will make a list of entries and then create a DataFrame with the proper column names\n",
    "2. You can create a CSV file with a row for each entry. There are some formatting that you need to be aware of.  That is the column names and making sure that date-times are YYYY-MM-DDThh:mm:ss\n",
    "\n",
    "\n",
    "| Column Name         |   Description                                                                                                 |\n",
    "| ------------------- | --------------------------------------------------------------------------------------------------------------|\n",
    "| **network**         | [FDSN Network code (2 letters)](http://www.fdsn.org/networks/)                                                |\n",
    "| **station**         | [FDSN Station code (usually 5 characters)](https://ds.iris.edu/ds/nodes/dmc/data/formats/seed-channel-naming/)|\n",
    "| **location**        | [FDSN Location code (typically not used for MT)](http://docs.fdsn.org/projects/source-identifiers/en/v1.0/location-codes.html) |\n",
    "| **channel**         | [FDSN Channel code (3 characters)](http://docs.fdsn.org/projects/source-identifiers/en/v1.0/channel-codes.html)|\n",
    "| **start**           | Start time (YYYY-MM-DDThh:mm:ss) UTC |\n",
    "| **end**             | End time (YYYY-MM-DDThh:mm:ss) UTC  |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>network</th>\n",
       "      <th>station</th>\n",
       "      <th>location</th>\n",
       "      <th>channel</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EM</td>\n",
       "      <td>CAY10</td>\n",
       "      <td></td>\n",
       "      <td>LFE</td>\n",
       "      <td>2019-10-07T00:00:00</td>\n",
       "      <td>2019-10-30T00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EM</td>\n",
       "      <td>CAY10</td>\n",
       "      <td></td>\n",
       "      <td>LFN</td>\n",
       "      <td>2019-10-07T00:00:00</td>\n",
       "      <td>2019-10-30T00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EM</td>\n",
       "      <td>CAY10</td>\n",
       "      <td></td>\n",
       "      <td>LFZ</td>\n",
       "      <td>2019-10-07T00:00:00</td>\n",
       "      <td>2019-10-30T00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EM</td>\n",
       "      <td>CAY10</td>\n",
       "      <td></td>\n",
       "      <td>LQE</td>\n",
       "      <td>2019-10-07T00:00:00</td>\n",
       "      <td>2019-10-30T00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EM</td>\n",
       "      <td>CAY10</td>\n",
       "      <td></td>\n",
       "      <td>LQN</td>\n",
       "      <td>2019-10-07T00:00:00</td>\n",
       "      <td>2019-10-30T00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ZU</td>\n",
       "      <td>CAS04</td>\n",
       "      <td></td>\n",
       "      <td>LQE</td>\n",
       "      <td>2020-06-02T19:00:00</td>\n",
       "      <td>2020-07-13T19:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ZU</td>\n",
       "      <td>CAS04</td>\n",
       "      <td></td>\n",
       "      <td>LQN</td>\n",
       "      <td>2020-06-02T19:00:00</td>\n",
       "      <td>2020-07-13T19:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ZU</td>\n",
       "      <td>CAS04</td>\n",
       "      <td></td>\n",
       "      <td>LFE</td>\n",
       "      <td>2020-06-02T19:00:00</td>\n",
       "      <td>2020-07-13T19:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ZU</td>\n",
       "      <td>CAS04</td>\n",
       "      <td></td>\n",
       "      <td>LFN</td>\n",
       "      <td>2020-06-02T19:00:00</td>\n",
       "      <td>2020-07-13T19:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ZU</td>\n",
       "      <td>CAS04</td>\n",
       "      <td></td>\n",
       "      <td>LFZ</td>\n",
       "      <td>2020-06-02T19:00:00</td>\n",
       "      <td>2020-07-13T19:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ZU</td>\n",
       "      <td>NVR08</td>\n",
       "      <td></td>\n",
       "      <td>LQE</td>\n",
       "      <td>2020-06-02T19:00:00</td>\n",
       "      <td>2020-07-13T19:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ZU</td>\n",
       "      <td>NVR08</td>\n",
       "      <td></td>\n",
       "      <td>LQN</td>\n",
       "      <td>2020-06-02T19:00:00</td>\n",
       "      <td>2020-07-13T19:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ZU</td>\n",
       "      <td>NVR08</td>\n",
       "      <td></td>\n",
       "      <td>LFE</td>\n",
       "      <td>2020-06-02T19:00:00</td>\n",
       "      <td>2020-07-13T19:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ZU</td>\n",
       "      <td>NVR08</td>\n",
       "      <td></td>\n",
       "      <td>LFN</td>\n",
       "      <td>2020-06-02T19:00:00</td>\n",
       "      <td>2020-07-13T19:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ZU</td>\n",
       "      <td>NVR08</td>\n",
       "      <td></td>\n",
       "      <td>LFZ</td>\n",
       "      <td>2020-06-02T19:00:00</td>\n",
       "      <td>2020-07-13T19:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   network station location channel                start                  end\n",
       "0       EM   CAY10              LFE  2019-10-07T00:00:00  2019-10-30T00:00:00\n",
       "1       EM   CAY10              LFN  2019-10-07T00:00:00  2019-10-30T00:00:00\n",
       "2       EM   CAY10              LFZ  2019-10-07T00:00:00  2019-10-30T00:00:00\n",
       "3       EM   CAY10              LQE  2019-10-07T00:00:00  2019-10-30T00:00:00\n",
       "4       EM   CAY10              LQN  2019-10-07T00:00:00  2019-10-30T00:00:00\n",
       "5       ZU   CAS04              LQE  2020-06-02T19:00:00  2020-07-13T19:00:00\n",
       "6       ZU   CAS04              LQN  2020-06-02T19:00:00  2020-07-13T19:00:00\n",
       "7       ZU   CAS04              LFE  2020-06-02T19:00:00  2020-07-13T19:00:00\n",
       "8       ZU   CAS04              LFN  2020-06-02T19:00:00  2020-07-13T19:00:00\n",
       "9       ZU   CAS04              LFZ  2020-06-02T19:00:00  2020-07-13T19:00:00\n",
       "10      ZU   NVR08              LQE  2020-06-02T19:00:00  2020-07-13T19:00:00\n",
       "11      ZU   NVR08              LQN  2020-06-02T19:00:00  2020-07-13T19:00:00\n",
       "12      ZU   NVR08              LFE  2020-06-02T19:00:00  2020-07-13T19:00:00\n",
       "13      ZU   NVR08              LFN  2020-06-02T19:00:00  2020-07-13T19:00:00\n",
       "14      ZU   NVR08              LFZ  2020-06-02T19:00:00  2020-07-13T19:00:00"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Uncomment to test multi network MTH5s\n",
    "\n",
    "EMCAY10LFE = ['EM', 'CAY10', '', 'LFE', '2019-10-07T00:00:00', '2019-10-30T00:00:00'] \n",
    "EMCAY10LFN = ['EM', 'CAY10', '', 'LFN', '2019-10-07T00:00:00', '2019-10-30T00:00:00'] \n",
    "EMCAY10LFZ = ['EM', 'CAY10', '', 'LFZ', '2019-10-07T00:00:00', '2019-10-30T00:00:00'] \n",
    "EMCAY10LQE = ['EM', 'CAY10', '', 'LQE', '2019-10-07T00:00:00', '2019-10-30T00:00:00'] \n",
    "EMCAY10LQN = ['EM', 'CAY10', '', 'LQN', '2019-10-07T00:00:00', '2019-10-30T00:00:00'] \n",
    "ZUCAS04LQ1 = ['ZU', 'CAS04', '', 'LQE', '2020-06-02T19:00:00', '2020-07-13T19:00:00']\n",
    "ZUCAS04LQ2 = ['ZU', 'CAS04', '', 'LQN', '2020-06-02T19:00:00', '2020-07-13T19:00:00']\n",
    "ZUCAS04BF1 = ['ZU', 'CAS04', '', 'LFE', '2020-06-02T19:00:00', '2020-07-13T19:00:00']\n",
    "ZUCAS04BF2 = ['ZU', 'CAS04', '', 'LFN', '2020-06-02T19:00:00', '2020-07-13T19:00:00']\n",
    "ZUCAS04BF3 = ['ZU', 'CAS04', '', 'LFZ', '2020-06-02T19:00:00', '2020-07-13T19:00:00']\n",
    "ZUNRV08LQ1 = ['ZU', 'NVR08', '', 'LQE', '2020-06-02T19:00:00', '2020-07-13T19:00:00']\n",
    "ZUNRV08LQ2 = ['ZU', 'NVR08', '', 'LQN', '2020-06-02T19:00:00', '2020-07-13T19:00:00']\n",
    "ZUNRV08BF1 = ['ZU', 'NVR08', '', 'LFE', '2020-06-02T19:00:00', '2020-07-13T19:00:00']\n",
    "ZUNRV08BF2 = ['ZU', 'NVR08', '', 'LFN', '2020-06-02T19:00:00', '2020-07-13T19:00:00']\n",
    "ZUNRV08BF3 = ['ZU', 'NVR08', '', 'LFZ', '2020-06-02T19:00:00', '2020-07-13T19:00:00']\n",
    "request_list = [\n",
    "    EMCAY10LFE, EMCAY10LFN, EMCAY10LFZ, EMCAY10LQE, EMCAY10LQN,\n",
    "    ZUCAS04LQ1, ZUCAS04LQ2, ZUCAS04BF1, ZUCAS04BF2, ZUCAS04BF3,\n",
    "    ZUNRV08LQ1, ZUNRV08LQ2, ZUNRV08BF1, ZUNRV08BF2, ZUNRV08BF3\n",
    "]\n",
    "\n",
    "# Turn list into dataframe\n",
    "request_df =  pd.DataFrame(request_list, columns=m.column_names)\n",
    "request_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the request as a CSV\n",
    "\n",
    "Its helpful to be able to save the request as a CSV and modify it and use it later.  A CSV can be input as a request to `MakeMTH5`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "request_df.to_csv(default_path.joinpath(\"fdsn_request.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['EM', 'ZU'], dtype=object),\n",
       " array(['CAY10', 'CAS04', 'NVR08'], dtype=object),\n",
       " array([''], dtype=object),\n",
       " array(['LFE', 'LFN', 'LFZ', 'LQE', 'LQN'], dtype=object))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.unique_df_combo(request_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get only the metadata from IRIS\n",
    "\n",
    "It can be helpful to make sure that your request is what you would expect.  For that you can request only the metadata from IRIS.  The request is quick and light so shouldn't need to worry about the speed.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "inventory, data = m.get_inventory_from_df(request_df, data=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have a look at the Inventory to make sure it contains what is requested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Inventory created at 2021-11-01T20:06:51.481836Z\n",
       "\tCreated by: ObsPy 1.2.2\n",
       "\t\t    https://www.obspy.org\n",
       "\tSending institution: MTH5\n",
       "\tContains:\n",
       "\t\tNetworks (2):\n",
       "\t\t\tEM, ZU\n",
       "\t\tStations (3):\n",
       "\t\t\tEM.CAY10 (Indio Hills, CA, USA)\n",
       "\t\t\tZU.CAS04 (Corral Hollow, CA, USA)\n",
       "\t\t\tZU.NVR08 (Rhodes Salt Marsh, NV, USA)\n",
       "\t\tChannels (15):\n",
       "\t\t\tEM.CAY10..LFZ, EM.CAY10..LFN, EM.CAY10..LFE, EM.CAY10..LQN, \n",
       "\t\t\tEM.CAY10..LQE, ZU.CAS04..LFZ, ZU.CAS04..LFN, ZU.CAS04..LFE, \n",
       "\t\t\tZU.CAS04..LQN, ZU.CAS04..LQE, ZU.NVR08..LFZ, ZU.NVR08..LFN, \n",
       "\t\t\tZU.NVR08..LFE, ZU.NVR08..LQN, ZU.NVR08..LQE"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inventory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make an MTH5 from a request\n",
    "\n",
    "Now that we've created a request, and made sure that its what we expect, we can make an MTH5 file.  The input can be either the DataFrame or the CSV file.  \n",
    "\n",
    "We are going to time it just to get an indication how long it might take.  Should take about 2 minutes.\n",
    "\n",
    "**Note:** we are setting `interact=True` so we can interrogate the file when its complete.  If you want to just write a file leave `interact=False` the default. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-01 13:06:52,507 [line 593] mth5.mth5.MTH5.open_mth5 - WARNING: EMZU_CAY10_CAS04_NVR08.h5 will be overwritten in 'w' mode\n",
      "2021-11-01 13:06:52,981 [line 653] mth5.mth5.MTH5._initialize_file - INFO: Initialized MTH5 file C:\\Users\\jpeacock\\Documents\\GitHub\\mth5\\examples\\notebooks\\EMZU_CAY10_CAS04_NVR08.h5 in mode w\n",
      "2021-11-01 13:07:07,474 [line 481] mt_metadata.timeseries.stationxml.utils.XMLChannelMTChannel._xml_response_to_mt - INFO: Found an nnnamed filter, named it: 'coefficient_00'\n",
      "2021-11-01 13:07:07,486 [line 481] mt_metadata.timeseries.stationxml.utils.XMLChannelMTChannel._xml_response_to_mt - INFO: Found an nnnamed filter, named it: 'coefficient_00'\n",
      "2021-11-01 13:07:07,494 [line 481] mt_metadata.timeseries.stationxml.utils.XMLChannelMTChannel._xml_response_to_mt - INFO: Found an nnnamed filter, named it: 'coefficient_00'\n",
      "2021-11-01 13:07:07,502 [line 481] mt_metadata.timeseries.stationxml.utils.XMLChannelMTChannel._xml_response_to_mt - INFO: Found an nnnamed filter, named it: 'coefficient_00'\n",
      "2021-11-01 13:07:07,508 [line 481] mt_metadata.timeseries.stationxml.utils.XMLChannelMTChannel._xml_response_to_mt - INFO: Found an nnnamed filter, named it: 'coefficient_01'\n",
      "2021-11-01 13:07:07,518 [line 481] mt_metadata.timeseries.stationxml.utils.XMLChannelMTChannel._xml_response_to_mt - INFO: Found an nnnamed filter, named it: 'coefficient_00'\n",
      "2021-11-01 13:07:07,523 [line 481] mt_metadata.timeseries.stationxml.utils.XMLChannelMTChannel._xml_response_to_mt - INFO: Found an nnnamed filter, named it: 'coefficient_01'\n",
      "2021-11-01 13:07:07,558 [line 126] mt_metadata.base.metadata.station.add_run - WARNING: Run a is being overwritten with current information\n",
      "2021-11-01 13:07:07,730 [line 126] mt_metadata.base.metadata.station.add_run - WARNING: Run a is being overwritten with current information\n",
      "2021-11-01 13:07:10,047 [line 709] mth5.groups.base.Station.add_run - INFO: run 001 already exists, returning existing group.\n",
      "2021-11-01 13:07:10,567 [line 235] mth5.timeseries.run_ts.RunTS.validate_metadata - WARNING: end time of dataset 2019-10-11T23:04:44+00:00 does not match metadata end 2019-11-01T23:18:32+00:00 updating metatdata value to 2019-10-11T23:04:44+00:00\n",
      "2021-11-01 13:07:27,867 [line 332] mth5.groups.base.MasterStation.get_station - ERROR: CAS04 does not exist, check station_list for existing names\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jpeacock\\Documents\\GitHub\\mth5\\mth5\\groups\\master_station_run_channel.py\", line 326, in get_station\n",
      "    return StationGroup(self.hdf5_group[station_name], **self.dataset_options)\n",
      "  File \"h5py\\_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py\\_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "  File \"C:\\Users\\jpeacock\\Anaconda3\\envs\\mt\\lib\\site-packages\\h5py\\_hl\\group.py\", line 288, in __getitem__\n",
      "    oid = h5o.open(self.id, self._e(name), lapl=self._lapl)\n",
      "  File \"h5py\\_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py\\_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py\\h5o.pyx\", line 190, in h5py.h5o.open\n",
      "KeyError: \"Unable to open object (object 'CAS04' doesn't exist)\"\n"
     ]
    },
    {
     "ename": "MTH5Error",
     "evalue": "CAS04 does not exist, check station_list for existing names",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\Documents\\GitHub\\mth5\\mth5\\groups\\master_station_run_channel.py\u001b[0m in \u001b[0;36mget_station\u001b[1;34m(self, station_name)\u001b[0m\n\u001b[0;32m    325\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 326\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mStationGroup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhdf5_group\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstation_name\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset_options\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    327\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\mt\\lib\\site-packages\\h5py\\_hl\\group.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    287\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 288\u001b[1;33m             \u001b[0moid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5o\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_e\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lapl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    289\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\h5o.pyx\u001b[0m in \u001b[0;36mh5py.h5o.open\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"Unable to open object (object 'CAS04' doesn't exist)\"",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mMTH5Error\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\1/ipykernel_8772/1024756469.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mbegin\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMTime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mget_now_utc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmth5_object\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_mth5_from_fdsnclient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequest_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minteract\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMTime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mget_now_utc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\mth5\\mth5\\clients\\make_mth5.py\u001b[0m in \u001b[0;36mmake_mth5_from_fdsnclient\u001b[1;34m(self, df, path, client, interact)\u001b[0m\n\u001b[0;32m    203\u001b[0m                             \u001b[1;34mf\" and end times {len(trace_end_times)} from streams\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m                         )\n\u001b[1;32m--> 205\u001b[1;33m                     \u001b[0mrun_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_station\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsta_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msurvey_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroups_list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    206\u001b[0m                     \u001b[0mn_times\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrace_start_times\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\mth5\\mth5\\mth5.py\u001b[0m in \u001b[0;36mget_station\u001b[1;34m(self, station_name, survey)\u001b[0m\n\u001b[0;32m   1031\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfile_version\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1032\u001b[0m             \u001b[0msg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_survey\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msurvey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1033\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0msg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstations_group\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_station\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstation_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1034\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1035\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mremove_station\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstation_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msurvey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\mth5\\mth5\\groups\\master_station_run_channel.py\u001b[0m in \u001b[0;36mget_station\u001b[1;34m(self, station_name)\u001b[0m\n\u001b[0;32m    331\u001b[0m             )\n\u001b[0;32m    332\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 333\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mMTH5Error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    334\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    335\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mremove_station\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstation_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMTH5Error\u001b[0m: CAS04 does not exist, check station_list for existing names"
     ]
    }
   ],
   "source": [
    "begin = MTime(get_now_utc())\n",
    "\n",
    "mth5_object = m.make_mth5_from_fdsnclient(request_df, interact=True)\n",
    "\n",
    "end = MTime(get_now_utc())\n",
    "\n",
    "print(f\"Took {(int(et - st) // 60)}:{(et - st) % 60:05.2f} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the MTH5\n",
    "mth5_obj = mth5.MTH5()\n",
    "mth5_obj.open_mth5(mth5_file, mode=\"a\")\n",
    "print(mth5_obj.filename)\n",
    "mth5_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get time series from MTH5 data\n",
    "stations = mth5_obj.stations_group.station_summary\n",
    "stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mth5_obj.stations_group.channel_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the time series from a channel summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
