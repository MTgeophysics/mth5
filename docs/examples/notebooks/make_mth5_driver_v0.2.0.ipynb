{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make MTH5 from IRIS Data Managment Center v0.2.0 \n",
    "\n",
    "**Note:** this example assumes that data availability (Network, Station, Channel, Start, End) are all previously known.  If you do not know the data that you want to download use [IRIS tools](https://ds.iris.edu/ds/nodes/dmc/tools/##) to get data availability.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-24 18:05:10,341 [line 135] mth5.setup_logger - INFO: Logging file can be found C:\\Users\\jpeacock\\Documents\\GitHub\\mth5\\logs\\mth5_debug.log\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "from mth5.clients.make_mth5 import MakeMTH5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set the path to save files to as the current working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_path = Path().cwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize a MakeMTH5 object\n",
    "\n",
    "Here, we are setting the MTH5 file version to 0.2.0 so that we can have multiple surveys in a single file.  Also, setting the client to \"IRIS\".  Here, we are using `obspy.clients` tools for the request.  Here are the available [FDSN clients](https://docs.obspy.org/packages/obspy.clients.fdsn.html). \n",
    "\n",
    "**Note:** Only the \"IRIS\" client has been tested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = MakeMTH5(mth5_version='0.2.0')\n",
    "m.client = \"IRIS\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make the data inquiry as a DataFrame\n",
    "\n",
    "There are a few ways to make the inquiry to request data.  \n",
    "\n",
    "1. Make a DataFrame by hand.  Here we will make a list of entries and then create a DataFrame with the proper column names\n",
    "2. You can create a CSV file with a row for each entry. There are some formatting that you need to be aware of.  That is the column names and making sure that date-times are YYYY-MM-DDThh:mm:ss\n",
    "\n",
    "\n",
    "| Column Name         |   Description                                                                                                 |\n",
    "| ------------------- | --------------------------------------------------------------------------------------------------------------|\n",
    "| **network**         | [FDSN Network code (2 letters)](http://www.fdsn.org/networks/)                                                |\n",
    "| **station**         | [FDSN Station code (usually 5 characters)](https://ds.iris.edu/ds/nodes/dmc/data/formats/seed-channel-naming/)|\n",
    "| **location**        | [FDSN Location code (typically not used for MT)](http://docs.fdsn.org/projects/source-identifiers/en/v1.0/location-codes.html) |\n",
    "| **channel**         | [FDSN Channel code (3 characters)](http://docs.fdsn.org/projects/source-identifiers/en/v1.0/channel-codes.html)|\n",
    "| **start**           | Start time (YYYY-MM-DDThh:mm:ss) UTC |\n",
    "| **end**             | End time (YYYY-MM-DDThh:mm:ss) UTC  |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>network</th>\n",
       "      <th>station</th>\n",
       "      <th>location</th>\n",
       "      <th>channel</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EM</td>\n",
       "      <td>CAY10</td>\n",
       "      <td></td>\n",
       "      <td>LFE</td>\n",
       "      <td>2019-10-07T00:00:00</td>\n",
       "      <td>2019-10-30T00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EM</td>\n",
       "      <td>CAY10</td>\n",
       "      <td></td>\n",
       "      <td>LFN</td>\n",
       "      <td>2019-10-07T00:00:00</td>\n",
       "      <td>2019-10-30T00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EM</td>\n",
       "      <td>CAY10</td>\n",
       "      <td></td>\n",
       "      <td>LFZ</td>\n",
       "      <td>2019-10-07T00:00:00</td>\n",
       "      <td>2019-10-30T00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EM</td>\n",
       "      <td>CAY10</td>\n",
       "      <td></td>\n",
       "      <td>LQE</td>\n",
       "      <td>2019-10-07T00:00:00</td>\n",
       "      <td>2019-10-30T00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EM</td>\n",
       "      <td>CAY10</td>\n",
       "      <td></td>\n",
       "      <td>LQN</td>\n",
       "      <td>2019-10-07T00:00:00</td>\n",
       "      <td>2019-10-30T00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ZU</td>\n",
       "      <td>CAS04</td>\n",
       "      <td></td>\n",
       "      <td>LQE</td>\n",
       "      <td>2020-06-02T19:00:00</td>\n",
       "      <td>2020-07-13T19:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ZU</td>\n",
       "      <td>CAS04</td>\n",
       "      <td></td>\n",
       "      <td>LQN</td>\n",
       "      <td>2020-06-02T19:00:00</td>\n",
       "      <td>2020-07-13T19:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ZU</td>\n",
       "      <td>CAS04</td>\n",
       "      <td></td>\n",
       "      <td>LFE</td>\n",
       "      <td>2020-06-02T19:00:00</td>\n",
       "      <td>2020-07-13T19:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ZU</td>\n",
       "      <td>CAS04</td>\n",
       "      <td></td>\n",
       "      <td>LFN</td>\n",
       "      <td>2020-06-02T19:00:00</td>\n",
       "      <td>2020-07-13T19:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ZU</td>\n",
       "      <td>CAS04</td>\n",
       "      <td></td>\n",
       "      <td>LFZ</td>\n",
       "      <td>2020-06-02T19:00:00</td>\n",
       "      <td>2020-07-13T19:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ZU</td>\n",
       "      <td>NVR08</td>\n",
       "      <td></td>\n",
       "      <td>LQE</td>\n",
       "      <td>2020-06-02T19:00:00</td>\n",
       "      <td>2020-07-13T19:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ZU</td>\n",
       "      <td>NVR08</td>\n",
       "      <td></td>\n",
       "      <td>LQN</td>\n",
       "      <td>2020-06-02T19:00:00</td>\n",
       "      <td>2020-07-13T19:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ZU</td>\n",
       "      <td>NVR08</td>\n",
       "      <td></td>\n",
       "      <td>LFE</td>\n",
       "      <td>2020-06-02T19:00:00</td>\n",
       "      <td>2020-07-13T19:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ZU</td>\n",
       "      <td>NVR08</td>\n",
       "      <td></td>\n",
       "      <td>LFN</td>\n",
       "      <td>2020-06-02T19:00:00</td>\n",
       "      <td>2020-07-13T19:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ZU</td>\n",
       "      <td>NVR08</td>\n",
       "      <td></td>\n",
       "      <td>LFZ</td>\n",
       "      <td>2020-06-02T19:00:00</td>\n",
       "      <td>2020-07-13T19:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   network station location channel                start                  end\n",
       "0       EM   CAY10              LFE  2019-10-07T00:00:00  2019-10-30T00:00:00\n",
       "1       EM   CAY10              LFN  2019-10-07T00:00:00  2019-10-30T00:00:00\n",
       "2       EM   CAY10              LFZ  2019-10-07T00:00:00  2019-10-30T00:00:00\n",
       "3       EM   CAY10              LQE  2019-10-07T00:00:00  2019-10-30T00:00:00\n",
       "4       EM   CAY10              LQN  2019-10-07T00:00:00  2019-10-30T00:00:00\n",
       "5       ZU   CAS04              LQE  2020-06-02T19:00:00  2020-07-13T19:00:00\n",
       "6       ZU   CAS04              LQN  2020-06-02T19:00:00  2020-07-13T19:00:00\n",
       "7       ZU   CAS04              LFE  2020-06-02T19:00:00  2020-07-13T19:00:00\n",
       "8       ZU   CAS04              LFN  2020-06-02T19:00:00  2020-07-13T19:00:00\n",
       "9       ZU   CAS04              LFZ  2020-06-02T19:00:00  2020-07-13T19:00:00\n",
       "10      ZU   NVR08              LQE  2020-06-02T19:00:00  2020-07-13T19:00:00\n",
       "11      ZU   NVR08              LQN  2020-06-02T19:00:00  2020-07-13T19:00:00\n",
       "12      ZU   NVR08              LFE  2020-06-02T19:00:00  2020-07-13T19:00:00\n",
       "13      ZU   NVR08              LFN  2020-06-02T19:00:00  2020-07-13T19:00:00\n",
       "14      ZU   NVR08              LFZ  2020-06-02T19:00:00  2020-07-13T19:00:00"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EMCAY10LFE = ['EM', 'CAY10', '', 'LFE', '2019-10-07T00:00:00', '2019-10-30T00:00:00'] \n",
    "EMCAY10LFN = ['EM', 'CAY10', '', 'LFN', '2019-10-07T00:00:00', '2019-10-30T00:00:00'] \n",
    "EMCAY10LFZ = ['EM', 'CAY10', '', 'LFZ', '2019-10-07T00:00:00', '2019-10-30T00:00:00'] \n",
    "EMCAY10LQE = ['EM', 'CAY10', '', 'LQE', '2019-10-07T00:00:00', '2019-10-30T00:00:00'] \n",
    "EMCAY10LQN = ['EM', 'CAY10', '', 'LQN', '2019-10-07T00:00:00', '2019-10-30T00:00:00'] \n",
    "ZUCAS04LQ1 = ['ZU', 'CAS04', '', 'LQE', '2020-06-02T19:00:00', '2020-07-13T19:00:00']\n",
    "ZUCAS04LQ2 = ['ZU', 'CAS04', '', 'LQN', '2020-06-02T19:00:00', '2020-07-13T19:00:00']\n",
    "ZUCAS04BF1 = ['ZU', 'CAS04', '', 'LFE', '2020-06-02T19:00:00', '2020-07-13T19:00:00']\n",
    "ZUCAS04BF2 = ['ZU', 'CAS04', '', 'LFN', '2020-06-02T19:00:00', '2020-07-13T19:00:00']\n",
    "ZUCAS04BF3 = ['ZU', 'CAS04', '', 'LFZ', '2020-06-02T19:00:00', '2020-07-13T19:00:00']\n",
    "ZUNRV08LQ1 = ['ZU', 'NVR08', '', 'LQE', '2020-06-02T19:00:00', '2020-07-13T19:00:00']\n",
    "ZUNRV08LQ2 = ['ZU', 'NVR08', '', 'LQN', '2020-06-02T19:00:00', '2020-07-13T19:00:00']\n",
    "ZUNRV08BF1 = ['ZU', 'NVR08', '', 'LFE', '2020-06-02T19:00:00', '2020-07-13T19:00:00']\n",
    "ZUNRV08BF2 = ['ZU', 'NVR08', '', 'LFN', '2020-06-02T19:00:00', '2020-07-13T19:00:00']\n",
    "ZUNRV08BF3 = ['ZU', 'NVR08', '', 'LFZ', '2020-06-02T19:00:00', '2020-07-13T19:00:00']\n",
    "request_list = [\n",
    "    EMCAY10LFE, EMCAY10LFN, EMCAY10LFZ, EMCAY10LQE, EMCAY10LQN,\n",
    "    ZUCAS04LQ1, ZUCAS04LQ2, ZUCAS04BF1, ZUCAS04BF2, ZUCAS04BF3,\n",
    "    ZUNRV08LQ1, ZUNRV08LQ2, ZUNRV08BF1, ZUNRV08BF2, ZUNRV08BF3\n",
    "]\n",
    "\n",
    "# Turn list into dataframe\n",
    "request_df =  pd.DataFrame(request_list, columns=m.column_names)\n",
    "request_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the request as a CSV\n",
    "\n",
    "Its helpful to be able to save the request as a CSV and modify it and use it later.  A CSV can be input as a request to `MakeMTH5`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "request_df.to_csv(default_path.joinpath(\"fdsn_request.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get only the metadata from IRIS\n",
    "\n",
    "It can be helpful to make sure that your request is what you would expect.  For that you can request only the metadata from IRIS.  The request is quick and light so shouldn't need to worry about the speed.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "FDSNNoDataException",
     "evalue": "No data available for request.\nDetailed response of server:\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFDSNNoDataException\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\1/ipykernel_22416/663466057.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0minventory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_inventory_from_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequest_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Documents\\GitHub\\mth5\\mth5\\clients\\make_mth5.py\u001b[0m in \u001b[0;36mget_inventory_from_df\u001b[1;34m(self, df, client, data)\u001b[0m\n\u001b[0;32m    371\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnetwork\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mused_network\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    372\u001b[0m                 net_inv = client.get_stations(\n\u001b[1;32m--> 373\u001b[1;33m                     \u001b[0mrow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"network\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    374\u001b[0m                 )\n\u001b[0;32m    375\u001b[0m                 \u001b[0mreturned_network\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet_inv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnetworks\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\mt\\lib\\site-packages\\obspy\\clients\\fdsn\\client.py\u001b[0m in \u001b[0;36mget_stations\u001b[1;34m(self, starttime, endtime, startbefore, startafter, endbefore, endafter, network, station, location, channel, minlatitude, maxlatitude, minlongitude, maxlongitude, latitude, longitude, minradius, maxradius, level, includerestricted, includeavailability, updatedafter, matchtimeseries, filename, format, **kwargs)\u001b[0m\n\u001b[0;32m    723\u001b[0m             \"station\", DEFAULT_PARAMETERS['station'], kwargs)\n\u001b[0;32m    724\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 725\u001b[1;33m         \u001b[0mdata_stream\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_download\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    726\u001b[0m         \u001b[0mdata_stream\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    727\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\mt\\lib\\site-packages\\obspy\\clients\\fdsn\\client.py\u001b[0m in \u001b[0;36m_download\u001b[1;34m(self, url, return_string, data, use_gzip)\u001b[0m\n\u001b[0;32m   1395\u001b[0m             \u001b[0mdebug\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_string\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_string\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1396\u001b[0m             timeout=self.timeout, use_gzip=use_gzip)\n\u001b[1;32m-> 1397\u001b[1;33m         \u001b[0mraise_on_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1398\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1399\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\mt\\lib\\site-packages\\obspy\\clients\\fdsn\\client.py\u001b[0m in \u001b[0;36mraise_on_error\u001b[1;34m(code, data)\u001b[0m\n\u001b[0;32m   1721\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m204\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1722\u001b[0m         raise FDSNNoDataException(\"No data available for request.\",\n\u001b[1;32m-> 1723\u001b[1;33m                                   server_info)\n\u001b[0m\u001b[0;32m   1724\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mcode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m400\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1725\u001b[0m         msg = (\"Bad request. If you think your request was valid \"\n",
      "\u001b[1;31mFDSNNoDataException\u001b[0m: No data available for request.\nDetailed response of server:\n\n"
     ]
    }
   ],
   "source": [
    "inventory, data = m.get_inventory_from_df(request_df, data=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have a look at the Inventory to make sure it contains what is requested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inventory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make an MTH5 from a request\n",
    "\n",
    "Now that we've created a request, and made sure that its what we expect, we can make an MTH5 file.  The input can be either the DataFrame or the CSV file.  \n",
    "\n",
    "We are going to time it just to get an indication how long it might take.  Should take about 4 minutes.\n",
    "\n",
    "**Note:** we are setting `interact=True` so we can interrogate the file when its complete.  If you want to just write a file leave `interact=False` the default. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "mth5_object = m.make_mth5_from_fdsnclient(request_df, interact=True)\n",
    "\n",
    "print(f\"Created {mth5_object.filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Have a look at the contents of the created file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mth5_object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a DataFrame that summarizes each channel dataset\n",
    "\n",
    "**Note:** This is quite slow because attribute access is not optimized for speed.  And the MTH5 code used for this summary table is not optimized.  You should only do this once for a given file.  Also, note the `hdf5_reference` column.  This is an internal reference for an open HDF5 file and can be used to directly access a group or dataset.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "\n",
    "mth5_object.channel_summary.clear_table()\n",
    "mth5_object.channel_summary.summarize()\n",
    "\n",
    "ch_df = mth5_object.channel_summary.to_dataframe()\n",
    "ch_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## When you are finished be sure to close the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mth5_object.close_mth5()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
