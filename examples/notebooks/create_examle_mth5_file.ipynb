{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make an example MTH5 file\n",
    "\n",
    "This notebook will demonstrate how you can make an MTH5 file from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is a hack for now, once we have a real package with an install this should be removed.\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "from mth5 import mth5, timeseries\n",
    "from mt_metadata import timeseries as metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize MTH5 file\n",
    "\n",
    "By default the file will open in 'append' mode.  That means that if there is already a file of the same name, that file will be opened with the rights to append to it.  If you want to overwrite that file you can set the key work `mode='w'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/:\n",
       "====================\n",
       "    |- Group: Survey\n",
       "    ----------------\n",
       "        |- Group: Filters\n",
       "        -----------------\n",
       "        |- Group: Reports\n",
       "        -----------------\n",
       "        |- Group: Standards\n",
       "        -------------------\n",
       "            --> Dataset: summary\n",
       "            ......................\n",
       "        |- Group: Stations\n",
       "        ------------------"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mth5_obj = mth5.MTH5()\n",
    "mth5_obj.open_mth5(Path(Path.cwd(), \"example.h5\"), mode=\"a\")\n",
    "mth5_obj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add a new station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/Survey/Stations/mt001:\n",
       "===================="
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_station = mth5_obj.add_station(\"mt001\")\n",
    "new_station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mt001'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_station.metadata.id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update Station metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "    \"station\": {\n",
       "        \"acquired_by.author\": null,\n",
       "        \"channels_recorded\": [],\n",
       "        \"data_type\": null,\n",
       "        \"geographic_name\": null,\n",
       "        \"hdf5_reference\": \"<HDF5 object reference>\",\n",
       "        \"id\": \"mt001\",\n",
       "        \"location.declination.model\": null,\n",
       "        \"location.declination.value\": null,\n",
       "        \"location.elevation\": 500.0,\n",
       "        \"location.latitude\": 40.0,\n",
       "        \"location.longitude\": -120.0,\n",
       "        \"mth5_type\": \"Station\",\n",
       "        \"orientation.method\": null,\n",
       "        \"orientation.reference_frame\": \"geographic\",\n",
       "        \"provenance.creation_time\": \"2021-03-17T22:31:41.042939+00:00\",\n",
       "        \"provenance.software.author\": null,\n",
       "        \"provenance.software.name\": null,\n",
       "        \"provenance.software.version\": null,\n",
       "        \"provenance.submitter.author\": null,\n",
       "        \"provenance.submitter.email\": null,\n",
       "        \"provenance.submitter.organization\": null,\n",
       "        \"run_list\": [],\n",
       "        \"time_period.end\": \"2020-01-05T14:00:00+00:00\",\n",
       "        \"time_period.start\": \"2020-01-01T12:00:00+00:00\"\n",
       "    }\n",
       "}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_station.metadata.time_period.start = \"2020-01-01T12:00:00\"\n",
    "new_station.metadata.time_period.end = \"2020-01-05T14:00:00\"\n",
    "new_station.metadata.location.latitude = 40.0\n",
    "new_station.metadata.location.longitude = -120\n",
    "new_station.metadata.location.elevation = 500\n",
    "new_station.metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPORTANT\n",
    "\n",
    "You need to call `write_metadata` which will update the group attributes from the metadata.  This is not automatic yet. You need to call `write_metadata` which will update the group attributes from the metadata.  This is not automatic yet for writing from scratch.  If you were to call `mth5_obj.add_station('mt001', station_metadata=station_metadata)` then `write_metadata` would be run automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'new_station' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-1304fea8ce55>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnew_station\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite_metadata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'new_station' is not defined"
     ]
    }
   ],
   "source": [
    "new_station.write_metadata()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "    \"run\": {\n",
       "        \"acquired_by.author\": null,\n",
       "        \"channels_recorded_auxiliary\": [],\n",
       "        \"channels_recorded_electric\": [],\n",
       "        \"channels_recorded_magnetic\": [],\n",
       "        \"data_logger.firmware.author\": null,\n",
       "        \"data_logger.firmware.name\": null,\n",
       "        \"data_logger.firmware.version\": null,\n",
       "        \"data_logger.id\": null,\n",
       "        \"data_logger.manufacturer\": null,\n",
       "        \"data_logger.timing_system.drift\": null,\n",
       "        \"data_logger.timing_system.type\": null,\n",
       "        \"data_logger.timing_system.uncertainty\": null,\n",
       "        \"data_logger.type\": null,\n",
       "        \"data_type\": null,\n",
       "        \"hdf5_reference\": \"<HDF5 object reference>\",\n",
       "        \"id\": \"mt001a\",\n",
       "        \"metadata_by.author\": null,\n",
       "        \"mth5_type\": \"Run\",\n",
       "        \"sample_rate\": 256.0,\n",
       "        \"time_period.end\": \"1980-01-01T00:00:00+00:00\",\n",
       "        \"time_period.start\": \"2020-01-01T12:00:00+00:00\"\n",
       "    }\n",
       "}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_run = new_station.add_run(\"mt001a\")\n",
    "new_run.metadata.sample_rate = 256\n",
    "new_run.metadata.time_period.start = \"2020-01-01T12:00:00\"\n",
    "new_run.metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPORTANT\n",
    "\n",
    "You need to call `write_metadata` which will update the group attributes from the metadata.  This is not automatic yet for writing from scratch.  If you were to call `mth5_obj.add_run('mt001', 'mt001a', run_metadata=run_metadata)` then `write_metadata` would be run automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_run.write_metadata()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add channels to the run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, component in enumerate([\"ex\", \"ey\"], 1):\n",
    "    e_metadata = metadata.Electric(**{\"time_period.start\": \"2020-01-01T12:00:00\",\n",
    "                                      \"time_period.end\": \"2020-01-02T12:00:00\",\n",
    "                                      \"sample_rate\": 256,\n",
    "                                      \"component\": component,\n",
    "                                      \"channel_number\": index,\n",
    "                                      \"dipole_length\": 100,\n",
    "                                      \"measurement_azimuth\": 0})\n",
    "    new_e = new_run.add_channel(component, \n",
    "                                 channel_type=\"electric\",\n",
    "                                 data=np.random.rand(4096),\n",
    "                                 channel_metadata=e_metadata)\n",
    "\n",
    "for index, component in enumerate([\"hx\", \"hy\", \"hz\"], 3):\n",
    "    h_metadata = metadata.Magnetic(**{\"time_period.start\": \"2020-01-01T12:00:00\",\n",
    "                        \"time_period.end\": \"2020-01-02T12:00:00\",\n",
    "                        \"sample_rate\": 256,\n",
    "                        \"component\": component,\n",
    "                        \"channel_number\": index,\n",
    "                        \"measurement_azimuth\": 0})\n",
    "    new_h = new_run.add_channel(component, \n",
    "                                 channel_type=\"magnetic\", \n",
    "                                 data=np.random.rand(4096),\n",
    "                                 channel_metadata=h_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/Survey/Stations/mt001:\n",
       "====================\n",
       "    |- Group: mt001a\n",
       "    ----------------\n",
       "        --> Dataset: ex\n",
       "        .................\n",
       "        --> Dataset: ey\n",
       "        .................\n",
       "        --> Dataset: hx\n",
       "        .................\n",
       "        --> Dataset: hy\n",
       "        .................\n",
       "        --> Dataset: hz\n",
       "        ................."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_station"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the summary table to make sure everything is there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-17 15:34:48,312 [line 118] mt_metadata.base.metadata.filtered.applied - ERROR: Filter.applied must be [True | False], not False\n",
      "2021-03-17 15:34:48,342 [line 118] mt_metadata.base.metadata.filtered.applied - ERROR: Filter.applied must be [True | False], not False\n",
      "2021-03-17 15:34:48,413 [line 118] mt_metadata.base.metadata.filtered.applied - ERROR: Filter.applied must be [True | False], not False\n",
      "2021-03-17 15:34:48,446 [line 118] mt_metadata.base.metadata.filtered.applied - ERROR: Filter.applied must be [True | False], not False\n",
      "2021-03-17 15:34:48,554 [line 118] mt_metadata.base.metadata.filtered.applied - ERROR: Filter.applied must be [True | False], not False\n",
      "2021-03-17 15:34:48,588 [line 118] mt_metadata.base.metadata.filtered.applied - ERROR: Filter.applied must be [True | False], not False\n",
      "2021-03-17 15:34:48,654 [line 118] mt_metadata.base.metadata.filtered.applied - ERROR: Filter.applied must be [True | False], not False\n",
      "2021-03-17 15:34:48,702 [line 118] mt_metadata.base.metadata.filtered.applied - ERROR: Filter.applied must be [True | False], not False\n",
      "2021-03-17 15:34:48,789 [line 118] mt_metadata.base.metadata.filtered.applied - ERROR: Filter.applied must be [True | False], not False\n",
      "2021-03-17 15:34:48,836 [line 118] mt_metadata.base.metadata.filtered.applied - ERROR: Filter.applied must be [True | False], not False\n",
      "2021-03-17 15:34:48,959 [line 118] mt_metadata.base.metadata.filtered.applied - ERROR: Filter.applied must be [True | False], not False\n",
      "2021-03-17 15:34:49,013 [line 118] mt_metadata.base.metadata.filtered.applied - ERROR: Filter.applied must be [True | False], not False\n",
      "2021-03-17 15:34:49,119 [line 118] mt_metadata.base.metadata.filtered.applied - ERROR: Filter.applied must be [True | False], not False\n",
      "2021-03-17 15:34:49,161 [line 118] mt_metadata.base.metadata.filtered.applied - ERROR: Filter.applied must be [True | False], not False\n",
      "2021-03-17 15:34:49,253 [line 118] mt_metadata.base.metadata.filtered.applied - ERROR: Filter.applied must be [True | False], not False\n",
      "2021-03-17 15:34:49,302 [line 118] mt_metadata.base.metadata.filtered.applied - ERROR: Filter.applied must be [True | False], not False\n",
      "2021-03-17 15:34:49,370 [line 118] mt_metadata.base.metadata.filtered.applied - ERROR: Filter.applied must be [True | False], not False\n",
      "2021-03-17 15:34:49,406 [line 118] mt_metadata.base.metadata.filtered.applied - ERROR: Filter.applied must be [True | False], not False\n",
      "2021-03-17 15:34:49,489 [line 118] mt_metadata.base.metadata.filtered.applied - ERROR: Filter.applied must be [True | False], not False\n",
      "2021-03-17 15:34:49,529 [line 118] mt_metadata.base.metadata.filtered.applied - ERROR: Filter.applied must be [True | False], not False\n",
      "2021-03-17 15:34:49,653 [line 118] mt_metadata.base.metadata.filtered.applied - ERROR: Filter.applied must be [True | False], not False\n",
      "2021-03-17 15:34:49,690 [line 118] mt_metadata.base.metadata.filtered.applied - ERROR: Filter.applied must be [True | False], not False\n",
      "2021-03-17 15:34:49,774 [line 118] mt_metadata.base.metadata.filtered.applied - ERROR: Filter.applied must be [True | False], not False\n",
      "2021-03-17 15:34:49,819 [line 118] mt_metadata.base.metadata.filtered.applied - ERROR: Filter.applied must be [True | False], not False\n",
      "2021-03-17 15:34:49,919 [line 118] mt_metadata.base.metadata.filtered.applied - ERROR: Filter.applied must be [True | False], not False\n",
      "2021-03-17 15:34:49,969 [line 118] mt_metadata.base.metadata.filtered.applied - ERROR: Filter.applied must be [True | False], not False\n",
      "2021-03-17 15:34:50,053 [line 118] mt_metadata.base.metadata.filtered.applied - ERROR: Filter.applied must be [True | False], not False\n",
      "2021-03-17 15:34:50,101 [line 118] mt_metadata.base.metadata.filtered.applied - ERROR: Filter.applied must be [True | False], not False\n",
      "2021-03-17 15:34:50,169 [line 118] mt_metadata.base.metadata.filtered.applied - ERROR: Filter.applied must be [True | False], not False\n",
      "2021-03-17 15:34:50,207 [line 118] mt_metadata.base.metadata.filtered.applied - ERROR: Filter.applied must be [True | False], not False\n",
      "2021-03-17 15:34:50,305 [line 118] mt_metadata.base.metadata.filtered.applied - ERROR: Filter.applied must be [True | False], not False\n",
      "2021-03-17 15:34:50,305 [line 477] mt_metadata.base.metadata.channel.set_attr_from_name - ERROR: negative.elevation is not in the current standards.  To properly add the attribute use add_base_attribute.\n",
      "2021-03-17 15:34:50,316 [line 478] mt_metadata.base.metadata.channel.set_attr_from_name - ERROR: 'Channel' object has no attribute 'negative'\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jpeacock\\Documents\\GitHub\\mt_metadata\\mt_metadata\\base\\metadata.py\", line 469, in set_attr_from_name\n",
      "    helpers.recursive_split_setattr(self, name, value)\n",
      "  File \"c:\\Users\\jpeacock\\Documents\\GitHub\\mt_metadata\\mt_metadata\\base\\helpers.py\", line 175, in recursive_split_setattr\n",
      "    base_object = getattr(base_object, key)\n",
      "AttributeError: 'Channel' object has no attribute 'negative'\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Channel' object has no attribute 'negative'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jpeacock\\Documents\\GitHub\\mt_metadata\\mt_metadata\\base\\metadata.py\u001b[0m in \u001b[0;36mset_attr_from_name\u001b[1;34m(self, name, value)\u001b[0m\n\u001b[0;32m    468\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 469\u001b[1;33m                 \u001b[0mhelpers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecursive_split_setattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    470\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jpeacock\\Documents\\GitHub\\mt_metadata\\mt_metadata\\base\\helpers.py\u001b[0m in \u001b[0;36mrecursive_split_setattr\u001b[1;34m(base_object, name, value, sep)\u001b[0m\n\u001b[0;32m    174\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 175\u001b[1;33m         \u001b[0mbase_object\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbase_object\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    176\u001b[0m         \u001b[0mrecursive_split_setattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbase_object\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Channel' object has no attribute 'negative'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-19be96a1bbbb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmth5_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstations_group\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchannel_summary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\jpeacock\\Documents\\GitHub\\mth5\\mth5\\groups\\master_station_run_channel.py\u001b[0m in \u001b[0;36mchannel_summary\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    203\u001b[0m                 \u001b[0mr_group\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRunGroup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms_group\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhdf5_group\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mr_group\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroups_list\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 205\u001b[1;33m                     \u001b[0mch_dataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mChannelDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr_group\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhdf5_group\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mch\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    206\u001b[0m                     \u001b[0mch_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mch_dataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchannel_entry\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[0mch_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jpeacock\\Documents\\GitHub\\mth5\\mth5\\groups\\master_station_run_channel.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, dataset, dataset_metadata, **kwargs)\u001b[0m\n\u001b[0;32m   1543\u001b[0m         \u001b[1;31m# channel data already exists then read them in with our writing back\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1544\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;34m\"mth5_type\"\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhdf5_dataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1545\u001b[1;33m             self.metadata.from_dict(\n\u001b[0m\u001b[0;32m   1546\u001b[0m                 \u001b[1;33m{\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhdf5_dataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"mth5_type\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhdf5_dataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1547\u001b[0m             )\n",
      "\u001b[1;32mc:\\Users\\jpeacock\\Documents\\GitHub\\mt_metadata\\mt_metadata\\base\\metadata.py\u001b[0m in \u001b[0;36mfrom_dict\u001b[1;34m(self, meta_dict)\u001b[0m\n\u001b[0;32m    605\u001b[0m         \u001b[1;31m# set attributes by key.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    606\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmeta_dict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 607\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_attr_from_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    608\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    609\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mto_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnested\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\" \"\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequired\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jpeacock\\Documents\\GitHub\\mt_metadata\\mt_metadata\\base\\metadata.py\u001b[0m in \u001b[0;36mset_attr_from_name\u001b[1;34m(self, name, value)\u001b[0m\n\u001b[0;32m    477\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    478\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 479\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    480\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m             \u001b[0msetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Channel' object has no attribute 'negative'"
     ]
    }
   ],
   "source": [
    "mth5_obj.stations_group.channel_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the summary table of the stations_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/:\n",
       "====================\n",
       "    |- Group: Survey\n",
       "    ----------------\n",
       "        |- Group: Filters\n",
       "        -----------------\n",
       "        |- Group: Reports\n",
       "        -----------------\n",
       "        |- Group: Standards\n",
       "        -------------------\n",
       "            --> Dataset: summary\n",
       "            ......................\n",
       "        |- Group: Stations\n",
       "        ------------------\n",
       "            |- Group: mt001\n",
       "            ---------------\n",
       "                |- Group: mt001a\n",
       "                ----------------\n",
       "                    --> Dataset: ex\n",
       "                    .................\n",
       "                    --> Dataset: ey\n",
       "                    .................\n",
       "                    --> Dataset: hx\n",
       "                    .................\n",
       "                    --> Dataset: hy\n",
       "                    .................\n",
       "                    --> Dataset: hz\n",
       "                    ................."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mth5_obj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add a channel from the time series object\n",
    "\n",
    "This is the common way that time series will actually be added to the MTH5 file.  Data will be read in from a file to create an mth5.timeseries.RunTS object which can then put into a run or channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_ts_list = []\n",
    "station_metadata = metadata.Station(id=\"mt001\")\n",
    "run_metadata = metadata.Run()\n",
    "run_metadata.id = \"mt001b\"\n",
    "run_metadata.sample_rate = 256\n",
    "run_metadata.time_period.start = \"2020-01-01T12:00:00\"\n",
    "\n",
    "# make electric channels\n",
    "for index, component in enumerate([\"ex\", \"ey\"], 1):\n",
    "    e_metadata = metadata.Electric(**{\"time_period.start\": \"2020-01-01T12:00:00\",\n",
    "                                      \"sample_rate\": 256,\n",
    "                                      \"component\": component,\n",
    "                                      \"channel_number\": index,\n",
    "                                      \"dipole_length\": 100,\n",
    "                                      \"measurement_azimuth\": 0})\n",
    "    ch = timeseries.ChannelTS(channel_type=\"electric\",\n",
    "                             data=np.random.rand(4096),\n",
    "                             channel_metadata=e_metadata,\n",
    "                             station_metadata=station_metadata,\n",
    "                             run_metadata=run_metadata)\n",
    "    channel_ts_list.append(ch)\n",
    "    \n",
    "# make magnetic channels\n",
    "for index, component in enumerate([\"hx\", \"hy\", \"hz\"], 3):\n",
    "    h_metadata = metadata.Magnetic(**{\"time_period.start\": \"2020-01-01T12:00:00\",\n",
    "                                      \"sample_rate\": 256,\n",
    "                                      \"component\": component,\n",
    "                                      \"channel_number\": index,\n",
    "                                      \"measurement_azimuth\": 0})\n",
    "    ch = timeseries.ChannelTS(channel_type=\"magnetic\",\n",
    "                             data=np.random.rand(4096),\n",
    "                             channel_metadata=h_metadata,\n",
    "                             station_metadata=station_metadata,\n",
    "                             run_metadata=run_metadata)\n",
    "    channel_ts_list.append(ch)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-04T14:46:45 [line 846] mth5.timeseries.RunTS.validate_metadata - WARNING: sample rate of dataset 256.0 does not match metadata sample rate None updating metatdata value to 256.0\n",
      "2020-12-04T14:46:45 [line 856] mth5.timeseries.RunTS.validate_metadata - WARNING: start time of dataset 2020-01-01T12:00:00+00:00 does not match metadata start 1980-01-01T00:00:00+00:00 updating metatdata value to 2020-01-01T12:00:00+00:00\n",
      "2020-12-04T14:46:45 [line 866] mth5.timeseries.RunTS.validate_metadata - WARNING: end time of dataset 2020-01-01T12:00:15.996093+00:00 does not match metadata end 1980-01-01T00:00:00+00:00 updating metatdata value to 2020-01-01T12:00:15.996093+00:00\n"
     ]
    }
   ],
   "source": [
    "# create a timeseries.RunTS object\n",
    "run_obj = timeseries.RunTS(array_list=channel_ts_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Channel Electric:\n",
       " -------------------\n",
       " \tcomponent:        ex\n",
       " \tdata type:        electric\n",
       " \tdata format:      float64\n",
       " \tdata shape:       (4096,)\n",
       " \tstart:            2020-01-01T12:00:00+00:00\n",
       " \tend:              2020-01-01T12:00:15.996093+00:00\n",
       " \tsample rate:      256.0,\n",
       " Channel Electric:\n",
       " -------------------\n",
       " \tcomponent:        ey\n",
       " \tdata type:        electric\n",
       " \tdata format:      float64\n",
       " \tdata shape:       (4096,)\n",
       " \tstart:            2020-01-01T12:00:00+00:00\n",
       " \tend:              2020-01-01T12:00:15.996093+00:00\n",
       " \tsample rate:      256.0,\n",
       " Channel Magnetic:\n",
       " -------------------\n",
       " \tcomponent:        hx\n",
       " \tdata type:        magnetic\n",
       " \tdata format:      float64\n",
       " \tdata shape:       (4096,)\n",
       " \tstart:            2020-01-01T12:00:00+00:00\n",
       " \tend:              2020-01-01T12:00:15.996093+00:00\n",
       " \tsample rate:      256.0,\n",
       " Channel Magnetic:\n",
       " -------------------\n",
       " \tcomponent:        hy\n",
       " \tdata type:        magnetic\n",
       " \tdata format:      float64\n",
       " \tdata shape:       (4096,)\n",
       " \tstart:            2020-01-01T12:00:00+00:00\n",
       " \tend:              2020-01-01T12:00:15.996093+00:00\n",
       " \tsample rate:      256.0,\n",
       " Channel Magnetic:\n",
       " -------------------\n",
       " \tcomponent:        hz\n",
       " \tdata type:        magnetic\n",
       " \tdata format:      float64\n",
       " \tdata shape:       (4096,)\n",
       " \tstart:            2020-01-01T12:00:00+00:00\n",
       " \tend:              2020-01-01T12:00:15.996093+00:00\n",
       " \tsample rate:      256.0]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_run_02 = new_station.add_run(\"mt001b\")\n",
    "new_run_02.from_runts(run_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "peacock",
   "language": "python",
   "name": "peacock"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
